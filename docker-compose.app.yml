services:
  api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: synthetic-data-api
    env_file:
      - .env
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - MLFLOW_S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=minioadmin
      - AWS_SECRET_ACCESS_KEY=minioadmin
      - PYTHONPATH=/app/src:/app/src/api/proto
    networks:
      - labellag_net
    ports:
      - "${API_PORT:-8000}:8000"
    command: [ "uv", "run", "uvicorn", "api.main:app", "--host", "0.0.0.0", "--port", "8000" ]
    restart: unless-stopped
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8000/health" ]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s

  analytics-crud:
    build:
      context: src/services/analytics-crud
      dockerfile: Dockerfile
    container_name: analytics-crud
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER:-synthetic}:${POSTGRES_PASSWORD:-synthetic_dev_password}@db:5432/${POSTGRES_DB:-synthetic_data}?sslmode=disable
      - PORT=50051
    networks:
      - labellag_net
    ports:
      - "${ANALYTICS_CRUD_PORT:-50051}:50051"
    depends_on:
      db:
        condition: service_healthy

  grpc-inference:
    build:
      context: .
      dockerfile: config/docker/grpc-inference.Dockerfile
    container_name: grpc-inference
    environment:
      - GRPC_INFERENCE_HOST=0.0.0.0
      - GRPC_INFERENCE_PORT=50052
      - GRPC_INFERENCE_DB_DSN=postgresql://${POSTGRES_USER:-synthetic}:${POSTGRES_PASSWORD:-synthetic_dev_password}@db:5432/${POSTGRES_DB:-synthetic_data}
      - GRPC_INFERENCE_MLFLOW_TRACKING_URI=http://mlflow:5000
      - GRPC_INFERENCE_INCLUDE_FEATURES_USED=true
    networks:
      - labellag_net
    ports:
      - "${GRPC_INFERENCE_PORT:-50052}:50052"
    depends_on:
      db:
        condition: service_healthy
      mlflow:
        condition: service_healthy
      minio:
        condition: service_healthy

  inference-gateway:
    build:
      context: src/services/inference-gateway
      dockerfile: Dockerfile
    container_name: inference-gateway
    environment:
      - PORT=8081
      - INFERENCE_GATEWAY_PYTHON_GRPC_ADDR=grpc-inference:50052
    networks:
      - labellag_net
    ports:
      - "${INFERENCE_GATEWAY_PORT:-8081}:8081"

  dashboard:
    build:
      context: src/ui
      dockerfile: Dockerfile
    container_name: synthetic-data-dashboard
    profiles: ["streamlit", "all"]
    environment:
      - API_BASE_URL=http://api:8000
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - MLFLOW_S3_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=minioadmin
      - AWS_SECRET_ACCESS_KEY=minioadmin
    networks:
      - labellag_net
    ports:
      - "${DASHBOARD_PORT:-8501}:8501"
    restart: unless-stopped
    depends_on:
      api:
        condition: service_healthy

  generator:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: synthetic-data-generator
    env_file:
      - .env
    volumes:
      - .:/app
      - /app/.venv
    networks:
      - labellag_net
    stdin_open: true
    tty: true

  # BFF (Backend for Frontend) - Node.js proxy layer for React UI
  bff:
    build:
      context: bff
      dockerfile: Dockerfile
    container_name: label-lag-bff
    profiles: ["react", "all"]
    environment:
      - BFF_PORT=3000
      - BFF_HOST=0.0.0.0
      - BFF_FASTAPI_BASE_URL=http://api:8000
      - BFF_MLFLOW_TRACKING_URI=http://mlflow:5000
      - BFF_INFERENCE_MODE=${BFF_INFERENCE_MODE:-fastapi}
      - BFF_GATEWAY_BASE_URL=http://inference-gateway:8081
      - BFF_REQUEST_TIMEOUT=30000
      - BFF_LOG_LEVEL=info
      - NODE_ENV=production
    networks:
      - labellag_net
    ports:
      - "${BFF_PORT:-3000}:3000"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3000/health"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 5s
    depends_on:
      api:
        condition: service_healthy

  # React Web UI
  web:
    build:
      context: web
      dockerfile: Dockerfile
    container_name: label-lag-web
    profiles: ["react", "all"]
    networks:
      - labellag_net
    ports:
      - "${WEB_PORT:-5173}:5173"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:5173/"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 5s
    depends_on:
      bff:
        condition: service_healthy

# Network labellag_net is defined in docker-compose.infra.yml.
# Run app with infra: -f docker-compose.infra.yml -f docker-compose.app.yml,
# or use the convenience wrapper (include). Do not run app compose alone.
